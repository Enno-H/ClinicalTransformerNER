# Clinical Transformer NER

## Aim
The package is the implementation of a transformer based NER system for clinical information extraction task. We aim to provide a simple and quick tool for researchers to conduct clinical NER without comprehensive knowledge of transformers. We also handle the sequence with length longer than the general transformer limits (512 tokens).

## Current available models
- BERT
- RoBERTa
- ALBERT
- ELECTRA

## Models will be included in future
- XLNet
- BART
- Reformer
- DistilBERT

## Usage and example
- TODO update after paper accept

## Organization
- Department of Health Outcomes and Biomedical Informatics, University of Florida

## authors
- Xi Yang
- Jiang Bian
- Yonghui Wu

## contact
- raise issue in our repo
- alexgre@ufl.edu

## reference
please cite our paper:


## MIMIC-III pretrained models
- we will release the MIMIC-III pretrained BERT, RoBERTa, ALBERT, and ELECTRA base models after paper accept